{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando o Spark no Windows\n",
    "\n",
    "#### Passo 1 - Instalando o Java\n",
    "\n",
    "Obter a versão mais recente do java [neste link](https://www.java.com/pt-BR/download/). Para verificar a versão que está instalada em sua máquina execute a seguinte linha de código no seu *prompt de comando*:\n",
    "\n",
    "```\n",
    "java -version\n",
    "```\n",
    "\n",
    "#### Passo 2 - Instalando o Python\n",
    "\n",
    "Fazer o download do Python disponível [neste link](https://www.python.org/downloads/windows/). Para verificar a versão do Python que está instalada em sua máquina, digitar o código no *prompt de comando*:\n",
    "\n",
    "```\n",
    "python --version\n",
    "```\n",
    "\n",
    "#### Passo 3 - Instalando o Apache Spark \n",
    "\n",
    "Selecionar a versão mais estável [neste link](http://spark.apache.org/downloads.html).\n",
    "\n",
    "<font color=red>Obs.: certifique-se de que o caminho onde os arquivos do Spark foram armazenados não contenham espaços (ex.: **\"C:\\spark\\spark-3.1.2-bin-hadoop2.7\"**).</font>\n",
    "\n",
    "#### Passo 4 - Instalando o findspark\n",
    "\n",
    "```\n",
    "pip install findspark\n",
    "```\n",
    "\n",
    "#### Passo 5 - Instalando o winutils\n",
    "\n",
    "Os arquivos do Spark não incluem o utilitário **winutils.exe** que é utilizado pelo Spark no Windows. Se não informar onde o Spark deve procurar este utilitário, veremos alguns erros no console e também não conseguiremos executar *scripts* Python utilizando o utilitário `spark-submit`.\n",
    "\n",
    "Faça o [download](https://github.com/steveloughran/winutils) para a versão do Hadoop para a qual sua instalação do Spark foi construída, apenas do arquivo **winutils.exe**.\n",
    "\n",
    "Crie a pasta **\"hadoop\\bin\"** dentro da pasta que contém os arquivos do Spark (do exemplo: **\"C:\\spark\\spark-3.1.2-bin-hadoop2.7\"**) e copie o arquivo **winutils.exe** para dentro desta pasta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = 'C:\\spark\\spark-3.4.1-bin-hadoop3'\n",
    "os.environ['JAVA_HOME'] = 'C:\\Program Files\\Java\\jre-1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-M8EDRUQ:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25c3a6d5710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
