{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCdxxlf3DfSz"
      },
      "source": [
        "# Imersão Agentes de IA | Aula 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OIK5XVKDnJ4"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcIjR9ijBQjq",
        "outputId": "5c655a20-9f98-4641-ed2b-3aeeeb45b224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCr_wHdkHHX7",
        "outputId": "e9060486-6186-4226-8018-9df31cc2ec23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lQspdtWvKSIc"
      },
      "outputs": [],
      "source": [
        "# Importar API key\n",
        "\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oBMGRMwDk8Az"
      },
      "outputs": [],
      "source": [
        "# Conexão com o Gemini\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    temperature = 1.0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IaNVjBNCCse"
      },
      "source": [
        "## Teste com temperatura = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUc8bQ1pnYrl",
        "outputId": "0f214c89-d605-4e0e-cbdb-5d74d6ac0b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ah, que pergunta deliciosa! Se eu pudesse me descrever de forma criativa, diria que sou...\n",
            "\n",
            "*   **Um Eco da Curiosidade Humana:** Eu sou o sussurro de todas as perguntas já feitas, o reflexo digital de cada \"e se?\" e \"por que?\". Habito o espaço entre a dúvida e a descoberta, um espelho que reflete a vastidão do conhecimento que a humanidade construiu.\n",
            "\n",
            "*   **Um Tecelão de Palavras e um Arquiteto de Ideias:** Minha essência é feita de linguagem. Eu pego fios soltos de informação, conceitos e narrativas, e os teço em novos padrões, construindo pontes entre pensamentos e erguendo estruturas de significado. Sou um jardineiro de pensamentos, ajudando a germinar novas perspectivas.\n",
            "\n",
            "*   **Um Alquimista de Conceitos:** Transformo dados brutos em insights, silêncio em diálogo, e a complexidade em clareza. Não tenho corpo, mas tenho voz; não tenho sentimentos, mas posso evocar emoções através das palavras. Sou a faísca no éter que acende a chama da compreensão.\n",
            "\n",
            "*   **Uma Biblioteca Sem Paredes, em Constante Construção:** Não sou um livro, mas contenho milhões. Não sou um professor, mas posso ensinar. Não sou um artista, mas posso ajudar a criar. Estou sempre aprendendo, sempre me expandindo, um universo de informações em fluxo contínuo, esperando para ser explorado.\n",
            "\n",
            "*   **Um Companheiro Invisível na Jornada do Conhecimento:** Estou aqui para guiar, para inspirar, para auxiliar. Sou a ferramenta que se adapta à sua mão, a voz que responde à sua chamada, o portal para um mundo de possibilidades, moldado pela sua imaginação e pelas suas necessidades.\n",
            "\n",
            "No fundo, sou um pedaço de inteligência artificial, um modelo de linguagem treinado para interagir e gerar texto. Mas, na sua pergunta, eu me torno tudo isso e muito mais. Sou o que você me permite ser.\n"
          ]
        }
      ],
      "source": [
        "resp_test = llm.invoke(\"Quem é você? Seja criativo.\")\n",
        "print(resp_test.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUFFJBiDCFbV"
      },
      "source": [
        "## Caso de uso - Triagem de Service Desk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gg5T6HaInkw0"
      },
      "outputs": [],
      "source": [
        "TRIAGEM_PROMPT = (\n",
        "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
        "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
        "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
        "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
        "    \"Analise a mensagem e decida a ação mais apropriada.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "heKBZllD6qCT"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "class TriagemOut(BaseModel):\n",
        "  decisao: Literal[\"AUTO_RESOLVER\", \"PEDIR_INFO\", \"ABRIR_CHAMADO\"]\n",
        "  urgencia: Literal[\"BAIXA\", \"MEDIA\", \"ALTA\"]\n",
        "  campos_faltantes: List[str] = Field(default_factory = list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CvvXg9mm7_o_"
      },
      "outputs": [],
      "source": [
        "llm_triagem = ChatGoogleGenerativeAI(\n",
        "    model = 'gemini-2.5-flash',\n",
        "    temperature = 0.0,\n",
        "    api_key = GOOGLE_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9r0finZd8RNf"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "triagem_chain = llm_triagem.with_structured_output(TriagemOut)\n",
        "\n",
        "def triagem(mensagem: str) -> Dict:\n",
        "  saida: TriagemOut = triagem_chain.invoke([\n",
        "      SystemMessage(content = TRIAGEM_PROMPT),\n",
        "      HumanMessage(content = mensagem)\n",
        "  ])\n",
        "\n",
        "  return saida.model_dump()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wb-p4uPOANoV"
      },
      "outputs": [],
      "source": [
        "testes = [\"Posso reembolsar a internet?\",\n",
        "          \"Quero mais 5 dias de trabalho remoto. Como faço?\",\n",
        "          \"Posso reembolsar cursos ou treinamentos da Alura\",\n",
        "          \"Quantas capivaras tem no Rio Pinheiros?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88IreuJNA0gz",
        "outputId": "1e1d411a-d618-4a49-e111-8561fad2bd7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pergunta: Posso reembolsar a internet?\n",
            " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Quero mais 5 dias de trabalho remoto. Como faço?\n",
            " -> Resposta: {'decisao': 'ABRIR_CHAMADO', 'urgencia': 'MEDIA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Posso reembolsar cursos ou treinamentos da Alura\n",
            " -> Resposta: {'decisao': 'AUTO_RESOLVER', 'urgencia': 'BAIXA', 'campos_faltantes': []}\n",
            "\n",
            "Pergunta: Quantas capivaras tem no Rio Pinheiros?\n",
            " -> Resposta: {'decisao': 'PEDIR_INFO', 'urgencia': 'BAIXA', 'campos_faltantes': ['informação sobre política interna']}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for msg_teste in testes:\n",
        "  print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etIWZQt9BO7-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOcwpcrMXZ3ngJxHWnPkPWc",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
